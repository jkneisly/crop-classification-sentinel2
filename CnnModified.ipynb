{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SDv69AEILRF"
   },
   "source": [
    "## Starter Notebook For The Côte d’Ivoire Byte-Sized Agriculture Challenge\n",
    "\n",
    "This starter notebook achieves the following:\n",
    "\n",
    "\n",
    "1.   Load & display satellite images\n",
    "2.   Build a basic machine learning model\n",
    "3.   Prepare the predictions for submission.\n",
    "\n",
    "The machine learning model shown here is by no mean ideal. Winning models should leverage multi-temporal data and not single-date imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mv5NkN-IM_z"
   },
   "source": [
    "# Processing  the GTIFF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdbCKvTfISKB"
   },
   "source": [
    "Here's a complete list of **Sentinel-2 bands** along with their **descriptions**, **wavelengths**, and **spatial resolutions**:\n",
    "\n",
    "---\n",
    "\n",
    "### 🛰️ **Sentinel-2 Band Overview**\n",
    "\n",
    "| Band | Name                    | Wavelength (nm) | Resolution (m) | Description |\n",
    "|------|-------------------------|-----------------|----------------|-------------|\n",
    "| B1   | Coastal aerosol         | 443             | 60             | Useful for atmospheric correction and aerosol detection. |\n",
    "| B2   | Blue                    | 490             | 10             | Penetrates water; used for vegetation, water bodies, and coastal mapping. |\n",
    "| B3   | Green                   | 560             | 10             | Good for assessing plant health and measuring biomass. |\n",
    "| B4   | Red                     | 665             | 10             | Key band for vegetation discrimination and chlorophyll absorption. |\n",
    "| B5   | Red Edge 1              | 705             | 20             | Useful for detecting subtle changes in vegetation. |\n",
    "| B6   | Red Edge 2              | 740             | 20             | Further detail on vegetation, especially stress and growth stages. |\n",
    "| B7   | Red Edge 3              | 783             | 20             | Extended vegetation monitoring. |\n",
    "| B8   | NIR (Near Infrared)     | 842             | 10             | Excellent for vegetation vigor, biomass, and land-water contrast. |\n",
    "| B8A  | Narrow NIR (Red Edge 4) | 865             | 20             | Sensitive to chlorophyll content and canopy structure. |\n",
    "| B9   | Water Vapor             | 945             | 60             | Atmospheric correction (water vapor absorption). |\n",
    "| B10  | SWIR – Cirrus           | 1375            | 60             | Detects high-altitude clouds (cirrus); not used for land analysis. |\n",
    "| B11  | SWIR 1                  | 1610            | 20             | Differentiates clouds, snow, and vegetation moisture. |\n",
    "| B12  | SWIR 2                  | 2190            | 20             | Useful for geology, soil, and burnt area mapping. |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Band Groupings by Application\n",
    "\n",
    "#### **RGB (Natural Color)**\n",
    "- **B4 (Red)**\n",
    "- **B3 (Green)**\n",
    "- **B2 (Blue)**\n",
    "\n",
    "#### **Vegetation Indices**\n",
    "- **NDVI:** B8 (NIR) & B4 (Red)\n",
    "- **EVI:** B8 (NIR), B4 (Red), B2 (Blue)\n",
    "- **SAVI:** B8 (NIR) & B4 (Red)\n",
    "- **NDRE:** B8A (Narrow NIR) & B5 (Red Edge)\n",
    "\n",
    "#### **Cloud/Atmosphere Analysis**\n",
    "- B1, B9, B10\n",
    "\n",
    "#### **Snow/Ice Monitoring**\n",
    "- B3, B11, B12\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:04:53.302552Z",
     "start_time": "2025-07-23T01:04:50.263391700Z"
    },
    "id": "2umBZVVwIof4"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install rasterio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:30:16.839803700Z",
     "start_time": "2025-07-23T01:30:15.057593100Z"
    },
    "id": "gVaDjRwFI-Rl"
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mBasicCnn\u001B[39;00m(nn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputImgChans, numClass, convKernelSize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, inputImgSize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m236\u001B[39m):\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class BasicCnn(nn.Module):\n",
    "\n",
    "    def __init__(self, inputImgChans, numClass, convKernelSize=3, inputImgSize=236):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnnStack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inputImgChans,out_channels=16,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16,out_channels=16,kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32,out_channels=32,kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=2304,out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512,out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128,out_features=numClass)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        outputs = self.cnnStack(inputs)\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-23T18:38:22.089017300Z",
     "start_time": "2025-07-23T18:38:21.693723300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.data_frame.iloc[idx]['tifPath'])\n",
    "        label = self.data_frame.iloc[idx]['class']\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(img_path) as src:\n",
    "                raster = src.read()  # (bands, height, width)\n",
    "            raster = torch.tensor(raster, dtype=torch.float32)\n",
    "            raster = raster[:,:48,:48]\n",
    "\n",
    "            label = torch.tensor(label, dtype=torch.long) - 1\n",
    "            return raster, label\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            return None, None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SkipConCnn(nn.Module):\n",
    "\n",
    "    def __init__(self, inputImgChans, numClass, convKernelSize=3, inputImgSize=236):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=inputImgChans,out_channels=16,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16,out_channels=16,kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.skip1 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=inputImgChans,out_channels=16,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.layer2 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32,out_channels=32,kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.skip2 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.layer3 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.skip3 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.linLayer = nn.ModuleList([\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=2304,out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512,out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128,out_features=numClass)\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layer1:\n",
    "            x = layer(x)\n",
    "        y = inputs\n",
    "        for layer in self.skip1:\n",
    "            y = layer(y)\n",
    "        inputs = x + y\n",
    "\n",
    "\n",
    "        x = inputs\n",
    "        for layer in self.layer2:\n",
    "            x = layer(x)\n",
    "        y = inputs\n",
    "        for layer in self.skip2:\n",
    "            y = layer(y)\n",
    "        inputs = x+y\n",
    "\n",
    "\n",
    "        x = inputs\n",
    "        for layer in self.layer3:\n",
    "            x = layer(x)\n",
    "        y = inputs\n",
    "        for layer in self.skip3:\n",
    "            y = layer(y)\n",
    "        outputs = x+y\n",
    "\n",
    "        for layer in self.linLayer:\n",
    "            outputs = layer(outputs)\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels_1x1, out_channels_3x3_reduce, out_channels_3x3,\n",
    "                 out_channels_5x5_reduce, out_channels_5x5, out_channels_pool):\n",
    "        super(InceptionModule, self).__init__()\n",
    "\n",
    "        self.layer1x1 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=out_channels_1x1,kernel_size=1,stride=1,padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels_1x1),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "        self.layer3x3 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=out_channels_3x3_reduce,kernel_size=1,stride=1,padding=0,bias=False),\n",
    "            nn.BatchNorm2d(out_channels_3x3_reduce),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels_3x3_reduce,out_channels=out_channels_3x3,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels_3x3),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "        self.layer5x5 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=out_channels_5x5_reduce,kernel_size=1,stride=1,padding=0,bias=False),\n",
    "            nn.BatchNorm2d(out_channels_5x5_reduce),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels_5x5_reduce,out_channels=out_channels_5x5,kernel_size=5,stride=1,padding=2,bias=False),\n",
    "            nn.BatchNorm2d(out_channels_5x5),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "        self.layerPool = nn.ModuleList([\n",
    "            nn.MaxPool2d(kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=out_channels_pool,kernel_size=5,stride=1,padding=2,bias=False),\n",
    "            nn.BatchNorm2d(out_channels_pool),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1 = x\n",
    "        for layer in self.layer1x1:\n",
    "            x1 = layer(x1)\n",
    "        x3 = x\n",
    "        for layer in self.layer3x3:\n",
    "            x3 = layer(x3)\n",
    "        x5 = x\n",
    "        for layer in self.layer5x5:\n",
    "            x5 = layer(x5)\n",
    "        xp = x\n",
    "        for layer in self.layerPool:\n",
    "            xp = layer(xp)\n",
    "\n",
    "        output = torch.cat([x1, x3, x5, xp],dim=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "class CnnSkipConInception(nn.Module):\n",
    "\n",
    "    def __init__(self,inputImgChans,numClass,convKernelSize=3,inputImgSize=236):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.ModuleList([\n",
    "            InceptionModule(inputImgChans, 16,16,16,16,16,16),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.skip1 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=inputImgChans,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.layer2 = nn.ModuleList([\n",
    "            InceptionModule(64, 32,32,32,32,32,32),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.skip2 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.layer3 = nn.ModuleList([\n",
    "            InceptionModule(128, 64,64,64,64,64,64),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.skip3 = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        ])\n",
    "\n",
    "        self.linLayer = nn.ModuleList([\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=9216,out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024,out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128,out_features=numClass)\n",
    "        ])\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layer1:\n",
    "            x = layer(x)\n",
    "        y = inputs\n",
    "        for layer in self.skip1:\n",
    "            y = layer(y)\n",
    "        inputs = x+y\n",
    "\n",
    "        x = inputs\n",
    "        for layer in self.layer2:\n",
    "            x = layer(x)\n",
    "        y = inputs\n",
    "        for layer in self.skip2:\n",
    "            y = layer(y)\n",
    "        inputs = x+y\n",
    "\n",
    "        x = inputs\n",
    "        for layer in self.layer3:\n",
    "            x = layer(x)\n",
    "        y = inputs\n",
    "        for layer in self.skip3:\n",
    "            y = layer(y)\n",
    "        outputs = x+y\n",
    "\n",
    "        for layer in self.linLayer:\n",
    "            outputs = layer(outputs)\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dataloaders(csv_file, root_dir, batch_size=32, train_split=0.8, transform=None, num_workers=4):\n",
    "    full_dataset = CustomImageDataset(csv_file=csv_file, root_dir=root_dir, transform=transform)\n",
    "\n",
    "    train_size = int(train_split * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if data is None:\n",
    "                continue\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                if data is None:\n",
    "                    continue\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:30:18.545956900Z",
     "start_time": "2025-07-23T01:30:18.540112700Z"
    },
    "id": "JPjO6avdKpLB"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    train_loader,val_loader = create_dataloaders(\n",
    "        csv_file=Path(\"S2Images/TrainDataset.csv\"),\n",
    "        root_dir=Path(''),\n",
    "        batch_size=128,\n",
    "        train_split=0.8,  # 80% train, 20% validation\n",
    "        transform=None,\n",
    "        num_workers=4\n",
    "    )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CnnSkipConInception(inputImgChans=12, numClass=3, convKernelSize=3, inputImgSize=48).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "    train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Assignment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
